# -*- coding: utf-8 -*-
"""TASK-B.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MWuR6wV3GFRQ6sLaqMbbya_fP7FGIpJg
"""

#import statements

import numpy as np
import pandas as pd
from sklearn.datasets import fetch_20newsgroups
from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import make_pipeline
from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report
import matplotlib.pyplot as plt
import seaborn as sns

# Step 1: Load the dataset
categories = ['alt.atheism', 'sci.space']
newsgroups_train = fetch_20newsgroups(subset='train', categories=categories)
newsgroups_test = fetch_20newsgroups(subset='test', categories=categories)

# Step 2: Explore the dataset
print("Categories:", newsgroups_train.target_names)
print("Number of training samples:", len(newsgroups_train.data))
print("Number of test samples:", len(newsgroups_test.data))
print("Sample data:", newsgroups_train.data[0])

# Step 3: Data Preprocessing
# Vectorizing the text data (convert text to numerical features)
count_vectorizer = CountVectorizer()
X_train_counts = count_vectorizer.fit_transform(newsgroups_train.data)

# Transform the counts to a normalized tf-idf representation
tfidf_transformer = TfidfTransformer()
X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)

# Step 4: Train the Naive Bayes Model
clf = MultinomialNB()
clf.fit(X_train_tfidf, newsgroups_train.target)

# Step 5: Make Predictions
X_test_counts = count_vectorizer.transform(newsgroups_test.data)
X_test_tfidf = tfidf_transformer.transform(X_test_counts)
predicted = clf.predict(X_test_tfidf)

# Step 6: Evaluate the Model
accuracy = accuracy_score(newsgroups_test.target, predicted)
precision = precision_score(newsgroups_test.target, predicted, average='macro')
recall = recall_score(newsgroups_test.target, predicted, average='macro')

print(f"Accuracy: {accuracy}")
print(f"Precision: {precision}")
print(f"Recall: {recall}")

# Detailed Evaluation
conf_matrix = confusion_matrix(newsgroups_test.target, predicted)
print("Confusion Matrix:\n", conf_matrix)
class_report = classification_report(newsgroups_test.target, predicted, target_names=categories)
print("Classification Report:\n", class_report)

# Visualize the Confusion Matrix
plt.figure(figsize=(10, 7))
sns.heatmap(conf_matrix, annot=True, fmt='d', xticklabels=categories, yticklabels=categories)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

# Step 7: Create a Pipeline (for future use and convenience)
text_clf = make_pipeline(CountVectorizer(), TfidfTransformer(), MultinomialNB())
text_clf.fit(newsgroups_train.data, newsgroups_train.target)

# Predict using the pipeline
predicted_pipeline = text_clf.predict(newsgroups_test.data)

# Evaluate the pipeline model
accuracy_pipeline = accuracy_score(newsgroups_test.target, predicted_pipeline)
precision_pipeline = precision_score(newsgroups_test.target, predicted_pipeline, average='macro')
recall_pipeline = recall_score(newsgroups_test.target, predicted_pipeline, average='macro')

print(f"Pipeline Accuracy: {accuracy_pipeline}")
print(f"Pipeline Precision: {precision_pipeline}")
print(f"Pipeline Recall: {recall_pipeline}")

# Additional visualization: Distribution of classes
plt.figure(figsize=(8, 6))
sns.countplot(newsgroups_train.target)
plt.title('Distribution of Classes in Training Data')
plt.xlabel('Class')
plt.ylabel('Frequency')
plt.xticks(ticks=[0, 1], labels=categories)
plt.show()



# Analyze misclassifications
misclassified_indices = np.where(newsgroups_test.target != predicted)[0]
print(f"Number of misclassified samples: {len(misclassified_indices)}")
for i in range(5):  # Display a few examples
    idx = misclassified_indices[i]
    print(f"Original: {categories[newsgroups_test.target[idx]]}, Predicted: {categories[predicted[idx]]}")
    print(newsgroups_test.data[idx])
    print("----")

# Save the model (optional)
import joblib
joblib.dump(text_clf, 'text_classifier_model.pkl')
print("Model saved as 'text_classifier_model.pkl'")

# Load the model (optional)
loaded_model = joblib.load('text_classifier_model.pkl')
print("Loaded model and re-evaluate:")
loaded_predicted = loaded_model.predict(newsgroups_test.data)
loaded_accuracy = accuracy_score(newsgroups_test.target, loaded_predicted)
print(f"Loaded Model Accuracy: {loaded_accuracy}")

